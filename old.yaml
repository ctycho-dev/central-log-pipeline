version: '3.8'

x-healthcheck-zookeeper-template: &hc_zookeeper
  healthcheck:
    test: ["CMD-SHELL", "zookeeper-shell localhost:2181 ls / >/dev/null 2>&1"]
    interval: 20s
    timeout: 10s
    retries: 10
    start_period: 30s

x-healthcheck-kafka-template: &hc_kafka
  healthcheck:
    test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:9092", "--list"]
    interval: 30s
    timeout: 10s
    retries: 5
    start_period: 60s

x-healthcheck-logstash-template: &hc_logstash
  healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9600/_node/stats || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 90s

x-hc-es: &hc_es
  healthcheck:
    test: ["CMD-SHELL", "curl -sf -u healthcheck:${HEALTHCHECK_PASSWORD} http://localhost:9200/_cluster/health?wait_for_status=yellow&timeout=60s >/dev/null"]
    interval: 30s
    timeout: 30s
    retries: 20
    start_period: 90s

x-hc-kbn: &hc_kbn
  healthcheck:
    test: ["CMD-SHELL", "curl -sf -u healthcheck:${HEALTHCHECK_PASSWORD} http://localhost:5601/api/status >/dev/null"]
    interval: 30s
    timeout: 30s
    retries: 20
    start_period: 240s

services:
  zookeeper:
    container_name: zookeeper
    image: confluentinc/cp-zookeeper:7.5.3
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    networks: [central-log-pipeline]
    <<: *hc_zookeeper

  kafka:
    container_name: kafka
    image: confluentinc/cp-kafka:7.5.3
    ports:
      - "29092:29092"
    depends_on:
      zookeeper:
        condition: service_healthy
    environment:
      # Unique broker ID in the Kafka cluster
      KAFKA_BROKER_ID: 1
      # Connect to Zookeeper for cluster coordination
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      # Define two listeners: internal (container-to-container) and external (host-to-container)
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_HOST://0.0.0.0:29092
      # Tell clients how to connect: containers use kafka:9092, host uses localhost:29092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      # Map listener names to security protocols (no security = PLAINTEXT)
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      # Use internal listener for broker-to-broker communication
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      # Single node setup - only 1 replica for internal topics
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      # Automatically create topics when producers/consumers reference them
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    networks: [central-log-pipeline]
    <<: *hc_kafka

  logstash:
    container_name: logstash
    image: docker.elastic.co/logstash/logstash:8.11.3
    depends_on:
      kafka:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
    volumes:
      - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf
    environment:
      - LOGSTASH_API_KEY=${LOGSTASH_API_KEY}
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
    ports:
      - "5044:5044"
    networks: [central-log-pipeline]
    <<: *hc_logstash

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.3
    container_name: elasticsearch
    environment:
      # Single node + security
      - discovery.type=single-node
      - xpack.security.enabled=true
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}

      # Memory & locking
      - bootstrap.memory_lock=true
      - ES_JAVA_OPTS=-Xms1g -Xmx1g   # tune based on host RAM

      # *** ABSOLUTE DISK WATERMARKS ***
      # Choose values LOWER than your typical free space to avoid red due to thresholds.
      # Example for a small disk; adjust if you have more headroom.
      - cluster.routing.allocation.disk.watermark.low=5gb
      - cluster.routing.allocation.disk.watermark.high=3gb
      - cluster.routing.allocation.disk.watermark.flood_stage=1gb
      - cluster.routing.allocation.disk.threshold_enabled=true

      # (Optional) keep 1 shard, 0 replicas for single node; ILM/templates can set this per index later
      - action.auto_create_index=true
    ulimits:
      memlock: { soft: -1, hard: -1 }
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
    networks: [central-log-pipeline]
    restart: unless-stopped
    <<: *hc_es

  es-init-kibana-password:
    image: curlimages/curl:8.10.1
    depends_on:
      elasticsearch:
        condition: service_healthy
    environment:
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD:?Define ELASTIC_PASSWORD in .env}
      KIBANA_SYSTEM_PASSWORD: ${KIBANA_SYSTEM_PASSWORD:?Define KIBANA_SYSTEM_PASSWORD in .env}
    command: >
      sh -c '
        echo "Setting kibana_system password...";
        curl -sf -u elastic:${ELASTIC_PASSWORD} \
          -H "Content-Type: application/json" \
          -X POST http://elasticsearch:9200/_security/user/kibana_system/_password \
          -d "{\"password\":\"${KIBANA_SYSTEM_PASSWORD}\"}";
        echo "Done."
      '
    restart: "no"
    networks: [central-log-pipeline]
  es-init-healthcheck-user:
    image: curlimages/curl:8.10.1
    depends_on:
      elasticsearch:
        condition: service_healthy
    environment:
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD}
      HEALTHCHECK_PASSWORD: ${HEALTHCHECK_PASSWORD:?Define HEALTHCHECK_PASSWORD in .env}
    command: >
      sh -c '
        echo "Creating healthcheck role...";
        curl -sf -u elastic:${ELASTIC_PASSWORD} -H "Content-Type: application/json" \
          -X PUT http://elasticsearch:9200/_security/role/healthcheck -d "{\"cluster\":[\"monitor\"],\"indices\":[]}";
        echo "Creating healthcheck user...";
        curl -sf -u elastic:${ELASTIC_PASSWORD} -H "Content-Type: application/json" \
          -X POST http://elasticsearch:9200/_security/user/healthcheck -d "{\"password\":\"${HEALTHCHECK_PASSWORD}\",\"roles\":[\"healthcheck\"]}" || true;
        echo "Done."
      '
    restart: "no"
    networks: [central-log-pipeline]
  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.3
    container_name: kibana
    depends_on:
      elasticsearch:
        condition: service_healthy
      es-init-kibana-password:
        condition: service_completed_successfully
      es-init-healthcheck-user:
        condition: service_completed_successfully
    environment:
      ELASTICSEARCH_HOSTS: '["http://elasticsearch:9200"]'
      # Use the kibana_system account (password set below once)
      ELASTICSEARCH_USERNAME: kibana_system
      ELASTICSEARCH_PASSWORD: ${KIBANA_SYSTEM_PASSWORD}
      XPACK_SECURITY_ENCRYPTIONKEY: ${KIBANA_ENCRYPTION_KEY}
      XPACK_ENCRYPTEDSAVEDOBJECTS_ENCRYPTIONKEY: ${KIBANA_SAVEDOBJ_KEY}
      XPACK_REPORTING_ENCRYPTIONKEY: ${KIBANA_REPORTING_KEY}
    volumes:
      - kibana_data:/usr/share/kibana/data
    ports:
      - "5601:5601"
    networks: [central-log-pipeline]
    restart: unless-stopped
    <<: *hc_kbn

volumes:
  elasticsearch_data:
  kibana_data:

networks:
  central-log-pipeline:
    driver: bridge